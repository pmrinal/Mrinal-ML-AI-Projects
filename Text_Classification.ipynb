{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python:3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)]\n",
      "NLTK: 3.4.5\n",
      "sklearn: 0.22.1\n",
      "Pandas: 1.0.1\n",
      "Numpy: 1.18.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import nltk\n",
    "import sklearn\n",
    "import pandas\n",
    "import numpy\n",
    "\n",
    "print('Python:{}'.format(sys.version))\n",
    "print('NLTK: {}'.format(nltk.__version__))\n",
    "print('sklearn: {}'.format(sklearn.__version__))\n",
    "print('Pandas: {}'.format(pandas.__version__))\n",
    "print('Numpy: {}'.format(numpy.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Load the dataset of sms messges\n",
    "\n",
    "df = pd.read_table('SMSSpamCollection', header = None, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   0       5572 non-null   object\n",
      " 1   1       5572 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n",
      "None\n",
      "      0                                                  1\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...\n"
     ]
    }
   ],
   "source": [
    "# print useful information  about the data set\n",
    "\n",
    "print(df.info())\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham     4825\n",
      "spam     747\n",
      "Name: 0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check class distribution\n",
    "classes = df[0]\n",
    "print(classes.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     ham\n",
      "1     ham\n",
      "2    spam\n",
      "3     ham\n",
      "4     ham\n",
      "5    spam\n",
      "6     ham\n",
      "7     ham\n",
      "8    spam\n",
      "9    spam\n",
      "Name: 0, dtype: object\n",
      "[0 0 1 0 0 1 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "#convert class labels to binary values, 0 - ham, 1 - spam\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "Y = encoder.fit_transform(classes)\n",
    "\n",
    "print(classes[:10])\n",
    "print(Y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Go until jurong point, crazy.. Available only ...\n",
      "1                        Ok lar... Joking wif u oni...\n",
      "2    Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3    U dun say so early hor... U c already then say...\n",
      "4    Nah I don't think he goes to usf, he lives aro...\n",
      "5    FreeMsg Hey there darling it's been 3 week's n...\n",
      "6    Even my brother is not like to speak with me. ...\n",
      "7    As per your request 'Melle Melle (Oru Minnamin...\n",
      "8    WINNER!! As a valued network customer you have...\n",
      "9    Had your mobile 11 months or more? U R entitle...\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# store the SMS message data\n",
    "text_messages = df[1]\n",
    "print(text_messages[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Regular Expressions\n",
    "\n",
    "Some common regular expression metacharacters - copied from wikipedia\n",
    "\n",
    "^ Matches the starting position within the string. In line-based tools, it matches the starting position of any line.\n",
    "\n",
    ". Matches any single character (many applications exclude newlines, and exactly which characters are considered newlines is flavor-, character-encoding-, and platform-specific, but it is safe to assume that the line feed character is included). Within POSIX bracket expressions, the dot character matches a literal dot. For example, a.c matches \"abc\", etc., but [a.c] matches only \"a\", \".\", or \"c\".\n",
    "\n",
    "[ ] A bracket expression. Matches a single character that is contained within the brackets. For example, [abc] matches \"a\", \"b\", or \"c\". [a-z] specifies a range which matches any lowercase letter from \"a\" to \"z\". These forms can be mixed: [abcx-z] matches \"a\", \"b\", \"c\", \"x\", \"y\", or \"z\", as does [a-cx-z]. The - character is treated as a literal character if it is the last or the first (after the ^, if present) character within the brackets: [abc-], [-abc]. Note that backslash escapes are not allowed. The ] character can be included in a bracket expression if it is the first (after the ^) character: []abc].\n",
    "\n",
    "[^ ] Matches a single character that is not contained within the brackets. For example, [^abc] matches any character other than \"a\", \"b\", or \"c\". [^a-z] matches any single character that is not a lowercase letter from \"a\" to \"z\". Likewise, literal characters and ranges can be mixed.\n",
    "\n",
    "$ Matches the ending position of the string or the position just before a string-ending newline. In line-based tools, it matches the ending position of any line.\n",
    "\n",
    "( ) Defines a marked subexpression. The string matched within the parentheses can be recalled later (see the next entry, \\n). A marked subexpression is also called a block or capturing group. BRE mode requires ( ).\n",
    "\n",
    "\\n Matches what the nth marked subexpression matched, where n is a digit from 1 to 9. This construct is vaguely defined in the POSIX.2 standard. Some tools allow referencing more than nine capturing groups.\n",
    "\n",
    "* Matches the preceding element zero or more times. For example, abc matches \"ac\", \"abc\", \"abbbc\", etc. [xyz] matches \"\", \"x\", \"y\", \"z\", \"zx\", \"zyx\", \"xyzzy\", and so on. (ab)* matches \"\", \"ab\", \"abab\", \"ababab\", and so on.\n",
    "\n",
    "{m,n} Matches the preceding element at least m and not more than n times. For example, a{3,5} matches only \"aaa\", \"aaaa\", and \"aaaaa\". This is not found in a few older instances of regexes. BRE mode requires {m,n}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regexlib.com\n",
    "\n",
    "#use regular expression to replace email addresses, urls, phone numbers, other numbers, symbols\n",
    "\n",
    "#replace email addresses with 'emailaddr'\n",
    "processed = text_messages.str.replace(r'^.+@[^\\.].*\\.[a-z]{2,}$','emailaddr')\n",
    "\n",
    "#replace urls with 'webaddress'\n",
    "processed = processed.str.replace(r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$','webaddress')\n",
    "\n",
    "#replace money symbols with 'moneysymb'  - to get '£' pound sign press alt+156\n",
    "processed = processed.str.replace(r'£|\\$','moneysymb')\n",
    "\n",
    "#replace 10 digit phone number to 'phonenumber'\n",
    "processed = processed.str.replace(r'^\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}$','phonenumbr')\n",
    "\n",
    "#replace numbers with 'numbr'\n",
    "processed = processed.str.replace('\\d+(\\.\\d+)?','numbr')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove punctuation\n",
    "\n",
    "processed = processed.str.replace('[^\\w\\d\\s]', ' ')\n",
    "\n",
    "#replace whitespace between  terms with  a single space\n",
    "processed = processed.str.replace(r'\\s+',' ')\n",
    "\n",
    "#remove leading and training whitespace\n",
    "processed = processed.str.replace(r'^\\s+|\\s+?$','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       go until jurong point crazy available only in ...\n",
      "1                                 ok lar joking wif u oni\n",
      "2       free entry in numbr a wkly comp to win fa cup ...\n",
      "3             u dun say so early hor u c already then say\n",
      "4       nah i don t think he goes to usf he lives arou...\n",
      "                              ...                        \n",
      "5567    this is the numbrnd time we have tried numbr c...\n",
      "5568                  will ü b going to esplanade fr home\n",
      "5569    pity was in mood for that so any other suggest...\n",
      "5570    the guy did some bitching but i acted like i d...\n",
      "5571                            rofl its true to its name\n",
      "Name: 1, Length: 5572, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# changing to the lower case  hello, Hello, HELLO to hello all the same\n",
    "processed = processed.str.lower()\n",
    "print(processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stop words from text messages\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "processed = processed.apply(lambda x: ' '.join(term for term in x.split() if term not in stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove word stems using a Porter Stemmer\n",
    "\n",
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "processed = processed.apply(lambda x: ' '.join(ps.stem(term) for term in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       go jurong point crazi avail bugi n great world...\n",
      "1                                   ok lar joke wif u oni\n",
      "2       free entri numbr wkli comp win fa cup final tk...\n",
      "3                     u dun say earli hor u c alreadi say\n",
      "4                    nah think goe usf live around though\n",
      "                              ...                        \n",
      "5567    numbrnd time tri numbr contact u u moneysymbnu...\n",
      "5568                              ü b go esplanad fr home\n",
      "5569                                    piti mood suggest\n",
      "5570    guy bitch act like interest buy someth els nex...\n",
      "5571                                       rofl true name\n",
      "Name: 1, Length: 5572, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print (processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#creating a bag of words model\n",
    "all_words = []\n",
    "\n",
    "for message in processed:\n",
    "    words = word_tokenize(message)\n",
    "    for w in words:\n",
    "        all_words.append(w)\n",
    "        \n",
    "all_words = nltk.FreqDist(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words6579\n",
      "Most common words: [('numbr', 2648), ('u', 1207), ('call', 674), ('go', 456), ('get', 451), ('ur', 391), ('gt', 318), ('lt', 316), ('come', 304), ('moneysymbnumbr', 303), ('ok', 293), ('free', 284), ('day', 276), ('know', 275), ('love', 266)]\n"
     ]
    }
   ],
   "source": [
    "# print the total number of words and also 15 most common words\n",
    "print('Number of words{}'.format(len(all_words)))\n",
    "print('Most common words: {}'.format(all_words.most_common(15)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the 1500 most common words as features\n",
    "word_features = list(all_words.keys())[:1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go\n",
      "go\n",
      "go\n",
      "go\n",
      "go\n",
      "go\n",
      "go\n",
      "go\n",
      "go\n",
      "go\n",
      "go\n",
      "go\n",
      "go\n",
      "go\n",
      "go\n",
      "go\n"
     ]
    }
   ],
   "source": [
    "# define a find_feature function\n",
    "def find_feature(message):\n",
    "    words = word_tokenize(message)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features[word]=(word in words)\n",
    "    return features\n",
    "\n",
    "#Lets see some examples\n",
    "\n",
    "features = find_feature(processed[0])\n",
    "for key, value in features.items():\n",
    "    if value == True:\n",
    "        print(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go jurong point crazi avail bugi n great world la e buffet cine got amor wat'"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find features for all the messages\n",
    "\n",
    "messages = zip(processed, Y)\n",
    "\n",
    "#define a seed  for reproductibility\n",
    "\n",
    "seed = 1\n",
    "np.random.seed = seed\n",
    "##np.random.shuffle(messages)\n",
    "\n",
    "#call find_features function for each sms messages\n",
    "\n",
    "featuresets= [(find_feature(text), label) for (text, label) in messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "training, testing = model_selection.train_test_split(featuresets, test_size = 0.25, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training : 4179\n",
      "Testing : 1393\n"
     ]
    }
   ],
   "source": [
    "print('Training : {}'.format(len(training)))\n",
    "print('Testing : {}'.format(len(testing)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Scikit-Learn Classifiers with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model to train\n",
    "names = ['K Nearest Neighbors','Decision Tree','Random Forest', 'Logistic Regression','SGD Classifier','Naive Bayes','SVM' ]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    SGDClassifier(max_iter = 100),\n",
    "    MultinomialNB(),\n",
    "    SVC(kernel = 'linear')\n",
    "]\n",
    "\n",
    "models = zip(names,classifiers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Nearest Neighbors:Accuracy:94.11342426417804\n",
      "Decision Tree:Accuracy:97.5592246949031\n",
      "Random Forest:Accuracy:98.85139985642498\n",
      "Logistic Regression:Accuracy:98.27709978463747\n",
      "SGD Classifier:Accuracy:98.63603732950466\n",
      "Naive Bayes:Accuracy:98.63603732950466\n"
     ]
    }
   ],
   "source": [
    "#wrap models in NLTK\n",
    "\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "\n",
    "for name, model in models:\n",
    "    nltk_model = SklearnClassifier(model)\n",
    "    nltk_model.train(training)\n",
    "    accuracy = nltk.classify.accuracy(nltk_model, testing)*100\n",
    "    print('{}:Accuracy:{}'.format(name,accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensemble method - voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Method Accuracy:98.7078248384781\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "names = ['K Nearest Neighbors','Decision Tree','Random Forest', 'Logistic Regression','SGD Classifier','Naive Bayes','SVM' ]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    SGDClassifier(max_iter = 100),\n",
    "    MultinomialNB(),\n",
    "    SVC(kernel = 'linear')\n",
    "]\n",
    "\n",
    "models = list(zip(names,classifiers))\n",
    "\n",
    "nltk_ensemble =  SklearnClassifier(VotingClassifier(estimators = models, voting = 'hard',n_jobs = -1)) \n",
    "#hard voting and soft voting. when the classifiers are optimized you can go for soft voting. but when you need individually data then hard\n",
    "#n_jobs = -1 means the classifiers will run parallel\n",
    "\n",
    "nltk_ensemble.train(training)\n",
    "accuracy = nltk.classify.accuracy(nltk_ensemble, testing)*100\n",
    "print('Ensemble Method Accuracy:{}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make class level prediction for testing set\n",
    "\n",
    "txt_features, labels = list(zip(*testing)) \n",
    "prediction = nltk_ensemble.classify_many(txt_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      1208\n",
      "           1       0.98      0.92      0.95       185\n",
      "\n",
      "    accuracy                           0.99      1393\n",
      "   macro avg       0.99      0.96      0.97      1393\n",
      "weighted avg       0.99      0.99      0.99      1393\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">actual</th>\n",
       "      <th>ham</th>\n",
       "      <td>1205</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>15</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            predicted     \n",
       "                  ham spam\n",
       "actual ham       1205    3\n",
       "       spam        15  170"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print a confusion matrix and a classification report \n",
    "print(classification_report(labels, prediction))\n",
    "\n",
    "pd.DataFrame(\n",
    "    confusion_matrix(labels,prediction),\n",
    "    index = [['actual','actual'], ['ham','spam']],\n",
    "    columns = [['predicted','predicted'],['ham','spam']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
